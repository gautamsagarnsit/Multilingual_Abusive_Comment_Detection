{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba99c4a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-06T08:51:18.607146Z",
     "iopub.status.busy": "2021-12-06T08:51:18.605533Z",
     "iopub.status.idle": "2021-12-06T08:51:18.619422Z",
     "shell.execute_reply": "2021-12-06T08:51:18.618913Z",
     "shell.execute_reply.started": "2021-12-06T04:13:28.286918Z"
    },
    "papermill": {
     "duration": 0.038108,
     "end_time": "2021-12-06T08:51:18.619566",
     "exception": false,
     "start_time": "2021-12-06T08:51:18.581458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/multilingualabusivecomment/ShareChat-IndoML-Datathon-NSFW-CommentChallenge_Test_20_Percent_NoLabel.csv\n",
      "/kaggle/input/multilingualabusivecomment/ShareChat-IndoML-Datathon-NSFW-CommentChallenge_Train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c02d954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:51:18.663550Z",
     "iopub.status.busy": "2021-12-06T08:51:18.662644Z",
     "iopub.status.idle": "2021-12-06T08:51:25.926316Z",
     "shell.execute_reply": "2021-12-06T08:51:25.925383Z",
     "shell.execute_reply.started": "2021-12-06T04:13:28.328277Z"
    },
    "papermill": {
     "duration": 7.287296,
     "end_time": "2021-12-06T08:51:25.926464",
     "exception": false,
     "start_time": "2021-12-06T08:51:18.639168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f5cc68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:51:25.972816Z",
     "iopub.status.busy": "2021-12-06T08:51:25.972053Z",
     "iopub.status.idle": "2021-12-06T08:51:36.123774Z",
     "shell.execute_reply": "2021-12-06T08:51:36.123269Z",
     "shell.execute_reply.started": "2021-12-06T04:13:36.123631Z"
    },
    "papermill": {
     "duration": 10.177827,
     "end_time": "2021-12-06T08:51:36.123919",
     "exception": false,
     "start_time": "2021-12-06T08:51:25.946092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82246527ee754d978d46265e611be252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>randi ka deewana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>üëåüëåüôèü•∞ü•∞ü•∞‚òùÔ∏è‚òùÔ∏è</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>apni pant utar kar apni chut bhi to bata do madam ji kitni gori hogi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>krishnatripathi4578 jesi ghar ki sabhyata vaise sanskar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>is randi ko dusra kaam nahi hai kuttiya kahin ki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                                                  text  \\\n",
       "0  0  randi ka deewana                                                       \n",
       "1  1  üëåüëåüôèü•∞ü•∞ü•∞‚òùÔ∏è‚òùÔ∏è                                                             \n",
       "2  2  apni pant utar kar apni chut bhi to bata do madam ji kitni gori hogi   \n",
       "3  3  krishnatripathi4578 jesi ghar ki sabhyata vaise sanskar                \n",
       "4  4  is randi ko dusra kaam nahi hai kuttiya kahin ki                       \n",
       "\n",
       "  label  \n",
       "0  1     \n",
       "1  0     \n",
       "2  1     \n",
       "3  0     \n",
       "4  1     "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_location='../input/multilingualabusivecomment/ShareChat-IndoML-Datathon-NSFW-CommentChallenge_Train.csv'\n",
    "file=open(file_location,'r').read()\n",
    "total_lines=len(file.split('\\n'))\n",
    "label=[]\n",
    "text=[]\n",
    "id=[]\n",
    "with open(file_location,'r') as file:\n",
    "    for line in tqdm(file,total=total_lines-1): \n",
    "        tokens=line.split(',')\n",
    "        label.append(tokens[-1])\n",
    "        id_text=tokens[:2]\n",
    "        id.append(id_text[0])\n",
    "        text.append(id_text[1].rstrip('\\n'))\n",
    "df=pd.DataFrame()\n",
    "labels=[i.strip('\\n')[-1] for i in label]\n",
    "df['id']=id[1:]\n",
    "df['text']=text[1:]\n",
    "df['label']=labels[1:]\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "df.head()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9346de50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:51:36.370452Z",
     "iopub.status.busy": "2021-12-06T08:51:36.369219Z",
     "iopub.status.idle": "2021-12-06T08:51:36.813903Z",
     "shell.execute_reply": "2021-12-06T08:51:36.814315Z",
     "shell.execute_reply.started": "2021-12-06T04:13:47.058535Z"
    },
    "papermill": {
     "duration": 0.670374,
     "end_time": "2021-12-06T08:51:36.814465",
     "exception": false,
     "start_time": "2021-12-06T08:51:36.144091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500898 entries, 0 to 1500897\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   id      1500898 non-null  int64 \n",
      " 1   text    1500898 non-null  object\n",
      " 2   label   1500898 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 34.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.astype(dtype={\"id\":int, \"text\":str,'label':int})\n",
    "df.info()\n",
    "df['label'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386328bf",
   "metadata": {
    "papermill": {
     "duration": 0.020331,
     "end_time": "2021-12-06T08:51:36.855416",
     "exception": false,
     "start_time": "2021-12-06T08:51:36.835085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Embeddings That Can be Used**\n",
    "(a). https://www.cfilt.iitb.ac.in/~diptesh/embeddings/README.md\n",
    "1. as - Assamese\n",
    "2. bn - Bengali\n",
    "3. gu - Gujarati\n",
    "4. hi - Hindi\n",
    "5. kn - Kannada\n",
    "6. ko - Konkani\n",
    "8. ml - Malayalam\n",
    "9. mr - Marathi\n",
    "10. ne - Nepali\n",
    "11. pa - Punjabi\n",
    "12. sa - Sanskrit\n",
    "13. ta - Tamil\n",
    "14. te - Telugu\n",
    "\n",
    "(b). MuRIL\n",
    "<ol>\n",
    "    <li>Assamese</li>\n",
    "    <li>Bengali</li>\n",
    "    <li>English</li>\n",
    "    <li>Gujarati</li>\n",
    "    <li>Hindi</li>\n",
    "    <li>Kannada</li>\n",
    "    <li>Kashmiri</li>\n",
    "    <li>Malayalam</li>\n",
    "    <li>Marathi</li>\n",
    "    <li>Nepali</li>\n",
    "    <li>Oriya</li>\n",
    "    <li>Punjabi</li>\n",
    "    <li>Sanskrit</li>\n",
    "    <li>Sindhi</li>\n",
    "    <li>Tamil</li>\n",
    "    <li>Telugu</li>\n",
    "    <li>Urdu</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b282dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:51:36.904224Z",
     "iopub.status.busy": "2021-12-06T08:51:36.900754Z",
     "iopub.status.idle": "2021-12-06T08:51:36.906692Z",
     "shell.execute_reply": "2021-12-06T08:51:36.906264Z",
     "shell.execute_reply.started": "2021-12-06T04:13:47.721384Z"
    },
    "papermill": {
     "duration": 0.030637,
     "end_time": "2021-12-06T08:51:36.906802",
     "exception": false,
     "start_time": "2021-12-06T08:51:36.876165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=128):\n",
    "    \n",
    "    input_ids = []\n",
    "    tt_ids = []\n",
    "    at_ids = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
    "        text_chunk = texts[i:i+chunk_size]\n",
    "        encs = tokenizer(\n",
    "                    text_chunk,\n",
    "                    max_length = 128,\n",
    "                    padding='max_length',\n",
    "                    truncation=True\n",
    "                    )\n",
    "        \n",
    "        input_ids.extend(encs['input_ids'])\n",
    "        tt_ids.extend(encs['token_type_ids'])\n",
    "        at_ids.extend(encs['attention_mask'])\n",
    "    \n",
    "    return {'input_ids': input_ids, 'token_type_ids': tt_ids, 'attention_mask':at_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "158bfeb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:51:36.956431Z",
     "iopub.status.busy": "2021-12-06T08:51:36.955253Z",
     "iopub.status.idle": "2021-12-06T08:53:40.554383Z",
     "shell.execute_reply": "2021-12-06T08:53:40.554792Z",
     "shell.execute_reply.started": "2021-12-06T04:13:47.730167Z"
    },
    "papermill": {
     "duration": 123.6274,
     "end_time": "2021-12-06T08:53:40.554986",
     "exception": false,
     "start_time": "2021-12-06T08:51:36.927586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b182d5de1a584a30aa60c1def80fbb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c0faa822794d0eb20b37e611ca0454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac63d8b57ab4192bc5ba7c541b2277a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.02M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b236d3601445dfafbdc4e451517c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/113 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3517ff8eae64f2894b04b94bff3e783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b54345f80a4341bbe5bca574c1c7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=df['text']\n",
    "y=df['label']\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=5)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "train_encoding = fast_encode(list(X_train.values), tokenizer)\n",
    "val_encoding = fast_encode(list(X_val.values), tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10bdf84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:53:40.803530Z",
     "iopub.status.busy": "2021-12-06T08:53:40.772605Z",
     "iopub.status.idle": "2021-12-06T08:53:40.806284Z",
     "shell.execute_reply": "2021-12-06T08:53:40.805517Z",
     "shell.execute_reply.started": "2021-12-06T04:15:56.935618Z"
    },
    "papermill": {
     "duration": 0.228298,
     "end_time": "2021-12-06T08:53:40.806409",
     "exception": false,
     "start_time": "2021-12-06T08:53:40.578111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #item=defaultdict(dict)\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TwitterDataset(train_encoding, list(y_train))\n",
    "val_dataset = TwitterDataset(val_encoding, list(y_val))\n",
    "del train_encoding\n",
    "del val_encoding\n",
    "del X,y, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c17fd57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:53:40.861479Z",
     "iopub.status.busy": "2021-12-06T08:53:40.859856Z",
     "iopub.status.idle": "2021-12-06T08:53:40.864208Z",
     "shell.execute_reply": "2021-12-06T08:53:40.864600Z",
     "shell.execute_reply.started": "2021-12-06T04:15:57.144968Z"
    },
    "papermill": {
     "duration": 0.035623,
     "end_time": "2021-12-06T08:53:40.864734",
     "exception": false,
     "start_time": "2021-12-06T08:53:40.829111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MurilClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(MurilClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 197285, 128, 2\n",
    "        #D_in, H, D_out = 1536, 128, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.muril=AutoModelForMaskedLM.from_pretrained(\"google/muril-base-cased\")\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.muril.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.muril(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e4b8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:53:40.918418Z",
     "iopub.status.busy": "2021-12-06T08:53:40.917879Z",
     "iopub.status.idle": "2021-12-06T08:54:24.617993Z",
     "shell.execute_reply": "2021-12-06T08:54:24.617491Z",
     "shell.execute_reply.started": "2021-12-06T04:15:57.157777Z"
    },
    "papermill": {
     "duration": 43.730919,
     "end_time": "2021-12-06T08:54:24.618136",
     "exception": false,
     "start_time": "2021-12-06T08:53:40.887217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13add75e48f4dd4a8cd85c6b3732ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/909M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler,AdamW\n",
    "#from transformers BertForSequenceClassification\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"google/muril-base-cased\")\n",
    "model=MurilClassifier(freeze_bert=False)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "batch_size=32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader=DataLoader(val_dataset,batch_size=batch_size)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "#progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optim,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67335c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:54:24.673081Z",
     "iopub.status.busy": "2021-12-06T08:54:24.672483Z",
     "iopub.status.idle": "2021-12-06T08:54:24.675931Z",
     "shell.execute_reply": "2021-12-06T08:54:24.675504Z",
     "shell.execute_reply.started": "2021-12-06T04:16:29.914435Z"
    },
    "papermill": {
     "duration": 0.034329,
     "end_time": "2021-12-06T08:54:24.676043",
     "exception": false,
     "start_time": "2021-12-06T08:54:24.641714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print(\"Epoch:\",epoch)\n",
    "    total_loss=0\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            outputs=[]\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            #print('input id size',len(input_ids))\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            #print('Attention MAsk Size',len(attention_mask))\n",
    "            labels = batch['labels'].to(device)\n",
    "            #print('Label Size',len(labels))\n",
    "            #outputs = model(input_ids, attention_mask=attention_mask, labels=labels.unsqueeze(1))\n",
    "            logits=model(input_ids,attention_mask)\n",
    "            loss=loss_fn(logits,labels)  \n",
    "            total_loss+=loss.item()\n",
    "            #loss = outputs[0]\n",
    "            #print(\"Training Loss\",loss.item())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            lr_scheduler.step()\n",
    "            optim.zero_grad()\n",
    "            del input_ids\n",
    "            del attention_mask\n",
    "            del labels\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "    print(\"Training Loss:\",total_loss/batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7ad3d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:54:24.756067Z",
     "iopub.status.busy": "2021-12-06T08:54:24.755349Z",
     "iopub.status.idle": "2021-12-06T08:54:24.757470Z",
     "shell.execute_reply": "2021-12-06T08:54:24.757911Z",
     "shell.execute_reply.started": "2021-12-06T04:16:29.928757Z"
    },
    "papermill": {
     "duration": 0.057951,
     "end_time": "2021-12-06T08:54:24.758099",
     "exception": false,
     "start_time": "2021-12-06T08:54:24.700148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_acc=0\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    true_prediction=0\n",
    "    total_sample_size=0  \n",
    "    metric = load_metric(\"accuracy\")\n",
    "    with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            labels = batch['labels'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)            \n",
    "            attention_mask=batch['attention_mask'].to(device)\n",
    "            #batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                #out=model(**batch)\n",
    "                logits=model(input_ids,attention_mask)\n",
    "            l=loss_fn(logits,labels)\n",
    "            #l=out.loss\n",
    "            #prediction=torch.argmax(out.logits,dim=1)\n",
    "            #metric.add_batch(predictions=prediction, references=batch[\"labels\"])  \n",
    "            prediction=torch.argmax(logits,dim=1)\n",
    "            metric.add_batch(predictions=prediction, references=labels)\n",
    "            tepoch.set_postfix(loss=l.item())\n",
    "    accuracy=metric.compute()['accuracy']\n",
    "    print(\"Test Accuracy:\",accuracy)\n",
    "     # Save checkpoint for the model which yields best accuracy\n",
    "    if accuracy>=best_acc:\n",
    "        print(\"Saving checkpoint with accuracy = \",accuracy)\n",
    "        best_acc=accuracy\n",
    "        torch.save({\n",
    "            'epoch':epoch,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optim.state_dict(),\n",
    "            'loss':l,\n",
    "            'accuracy':best_acc\n",
    "        },'ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e8bfdc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:54:24.810433Z",
     "iopub.status.busy": "2021-12-06T08:54:24.808689Z",
     "iopub.status.idle": "2021-12-06T08:54:24.812594Z",
     "shell.execute_reply": "2021-12-06T08:54:24.813001Z",
     "shell.execute_reply.started": "2021-12-06T04:16:30.322992Z"
    },
    "papermill": {
     "duration": 0.031766,
     "end_time": "2021-12-06T08:54:24.813138",
     "exception": false,
     "start_time": "2021-12-06T08:54:24.781372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test(epoch):\n",
    "    best_acc=0\n",
    "    for i in range(1,epoch+1):\n",
    "        print(\"Training\")\n",
    "        train(i)\n",
    "        print(\"Testing\")\n",
    "        test(i)\n",
    "    print(\"Training ENDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6ed6936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:54:24.863959Z",
     "iopub.status.busy": "2021-12-06T08:54:24.863420Z",
     "iopub.status.idle": "2021-12-06T08:06:43.743506Z",
     "shell.execute_reply": "2021-12-06T08:06:43.742102Z",
     "shell.execute_reply.started": "2021-12-06T04:16:30.334975Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2021-12-06T08:54:24.836406",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8af0444d3646fcbce4fe19e2783fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37523 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f595674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:07:15.303668Z",
     "iopub.status.busy": "2021-12-06T08:07:15.302579Z",
     "iopub.status.idle": "2021-12-06T08:07:15.308045Z",
     "shell.execute_reply": "2021-12-06T08:07:15.306982Z",
     "shell.execute_reply.started": "2021-12-06T08:07:15.303617Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9a9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:07:15.310341Z",
     "iopub.status.busy": "2021-12-06T08:07:15.309851Z",
     "iopub.status.idle": "2021-12-06T08:07:22.570322Z",
     "shell.execute_reply": "2021-12-06T08:07:22.569549Z",
     "shell.execute_reply.started": "2021-12-06T08:07:15.310301Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def read_csv(path:str):\n",
    "    file = open(path, \"r\").read()\n",
    "    ix = []\n",
    "    ctx = []\n",
    "\n",
    "    for row in file.split(\"\\n\"):\n",
    "        l = re.sub(',(?!(?=[^\"]*\"[^\"]*(?:\"[^\"]*\"[^\"]*)*$))', \"\\t\", row)\n",
    "        try:\n",
    "            lk = l.split(\"\\t\")\n",
    "            if len(lk)>2 and len(lk[0])<6:\n",
    "                p,q= lk[0], lk[1]\n",
    "                ix.append(p)\n",
    "                ctx.append(q)\n",
    "            elif len(lk)==1 and lk[0]!='':\n",
    "                #print(lk)\n",
    "                p=lk[0].split(',')[0].rstrip('\\n')\n",
    "                q=lk[0].split(',')[0].rstrip('\\n')\n",
    "                ix.append(p)\n",
    "                ctx.append(q)    \n",
    "            \n",
    "            else:\n",
    "                lk=row.replace('\"', \" \")\n",
    "                lk=lk.split(\",\")\n",
    "                p,q = lk[0], lk[1]\n",
    "                ix.append(p)\n",
    "                ctx.append(q)\n",
    "        except Exception as e:\n",
    "            print(\"Exception occurred!.\", e)\n",
    "            print(f\"Length of ids obtained: {len(ix)}, and text: {len(ctx)}\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"CommentId\"]=ix[1:]\n",
    "    df[\"commentText\"]=ctx[1:]\n",
    "    df = df.astype(dtype={\"CommentId\":int, \"commentText\":str})\n",
    "    return df\n",
    "\n",
    "%time df = read_csv(\"../input/multilingualabusivecomment/ShareChat-IndoML-Datathon-NSFW-CommentChallenge_Test_20_Percent_NoLabel.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693d804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:07:22.571824Z",
     "iopub.status.busy": "2021-12-06T08:07:22.571597Z",
     "iopub.status.idle": "2021-12-06T08:07:25.070342Z",
     "shell.execute_reply": "2021-12-06T08:07:25.069576Z",
     "shell.execute_reply.started": "2021-12-06T08:07:22.571792Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344b230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:07:25.073644Z",
     "iopub.status.busy": "2021-12-06T08:07:25.073125Z",
     "iopub.status.idle": "2021-12-06T08:07:25.083914Z",
     "shell.execute_reply": "2021-12-06T08:07:25.083208Z",
     "shell.execute_reply.started": "2021-12-06T08:07:25.073606Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df['CommentId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a59ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:07:25.086031Z",
     "iopub.status.busy": "2021-12-06T08:07:25.085243Z",
     "iopub.status.idle": "2021-12-06T08:07:25.113966Z",
     "shell.execute_reply": "2021-12-06T08:07:25.113311Z",
     "shell.execute_reply.started": "2021-12-06T08:07:25.085996Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440f6b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:07:25.115759Z",
     "iopub.status.busy": "2021-12-06T08:07:25.115045Z",
     "iopub.status.idle": "2021-12-06T08:07:25.121724Z",
     "shell.execute_reply": "2021-12-06T08:07:25.121038Z",
     "shell.execute_reply.started": "2021-12-06T08:07:25.115723Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings,length):\n",
    "        self.encodings = encodings\n",
    "        self.length=length\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #item=defaultdict(dict)\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2aff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:07:25.123606Z",
     "iopub.status.busy": "2021-12-06T08:07:25.122909Z",
     "iopub.status.idle": "2021-12-06T08:07:25.131887Z",
     "shell.execute_reply": "2021-12-06T08:07:25.131108Z",
     "shell.execute_reply.started": "2021-12-06T08:07:25.12356Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model,test_loader):\n",
    "    model.eval()\n",
    "    all_prediction=[]\n",
    "    with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            input_ids = batch['input_ids'].to(device)            \n",
    "            attention_mask=batch['attention_mask'].to(device)\n",
    "            with torch.no_grad():\n",
    "                logits=model(input_ids,attention_mask)\n",
    "            prediction=torch.argmax(logits,dim=1)\n",
    "            all_prediction.append(prediction)\n",
    "    return [item.item() for sublist in all_prediction for item in sublist]\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d97032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:07:25.1339Z",
     "iopub.status.busy": "2021-12-06T08:07:25.133406Z",
     "iopub.status.idle": "2021-12-06T08:27:04.581184Z",
     "shell.execute_reply": "2021-12-06T08:27:04.580372Z",
     "shell.execute_reply.started": "2021-12-06T08:07:25.133863Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test=df['commentText']\n",
    "test_encoding = fast_encode(list(X_test.values), tokenizer)\n",
    "test_dataset = TestDataset(test_encoding,len(df['CommentId'].unique()))\n",
    "print(len(test_dataset))\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size)\n",
    "prediction = predict(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f2fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:31:06.03309Z",
     "iopub.status.busy": "2021-12-06T08:31:06.032835Z",
     "iopub.status.idle": "2021-12-06T08:31:06.102867Z",
     "shell.execute_reply": "2021-12-06T08:31:06.102105Z",
     "shell.execute_reply.started": "2021-12-06T08:31:06.033061Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission=pd.DataFrame()\n",
    "submission['commentId']=df['CommentId']\n",
    "submission['Label']=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a15b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:31:07.921235Z",
     "iopub.status.busy": "2021-12-06T08:31:07.920915Z",
     "iopub.status.idle": "2021-12-06T08:31:07.937523Z",
     "shell.execute_reply": "2021-12-06T08:31:07.936829Z",
     "shell.execute_reply.started": "2021-12-06T08:31:07.921199Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b44908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:31:11.034996Z",
     "iopub.status.busy": "2021-12-06T08:31:11.034424Z",
     "iopub.status.idle": "2021-12-06T08:31:11.244833Z",
     "shell.execute_reply": "2021-12-06T08:31:11.2441Z",
     "shell.execute_reply.started": "2021-12-06T08:31:11.034956Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('Submission.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b1f3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T08:31:13.430753Z",
     "iopub.status.busy": "2021-12-06T08:31:13.430167Z",
     "iopub.status.idle": "2021-12-06T08:31:13.436163Z",
     "shell.execute_reply": "2021-12-06T08:31:13.435415Z",
     "shell.execute_reply.started": "2021-12-06T08:31:13.430713Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-06T08:51:10.346926",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}